from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
import os
import json
import uvicorn
import asyncio
import datetime

from dotenv import load_dotenv, find_dotenv

try:
    from motor.motor_asyncio import AsyncIOMotorClient  # type: ignore
except Exception:
    AsyncIOMotorClient = None  # type: ignore

app = FastAPI(title="IELTS Reading Module API", version="1.0.0")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {"message": "Reading Module API - GeliÅŸtirici: AZROS", "status": "ready"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "module": "reading"}

# --------- Data models ---------

class Question(BaseModel):
    id: str
    type: str  # TrueFalseNotGiven, MultipleChoice, MatchingHeadings, FillInTheBlanks
    prompt: str
    options: Optional[List[str]] = None
    passage_id: Optional[str] = None
    answer: Optional[Any] = None  # Eski format iÃ§in geriye uyumluluk
    correct_answer: Optional[Any] = None  # Yeni format

class Passage(BaseModel):
    id: str
    title: str
    text: str

class ReadingTest(BaseModel):
    id: str
    source: str = Field(description="Kaynak / test adÄ±")
    passages: List[Passage]
    questions: List[Question]

class SubmitAnswersRequest(BaseModel):
    test_id: str
    answers: Dict[str, Any]
    user_id: Optional[str] = None
    test_data: Optional[Dict[str, Any]] = None  # Frontend'den gelen test verisi

class AIScoreFeedback(BaseModel):
    band_estimate: float
    strengths: List[str]
    improvements: List[str]
    tips: List[str]

DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data", "reading")
TESTS_FILE = os.path.join(DATA_DIR, "tests.json")

# -------------- MongoDB Setup --------------
# Load .env from project root even if cwd is modules/
try:
    env_path = find_dotenv()
    if env_path:
        load_dotenv(env_path)
    else:
        load_dotenv()
except Exception:
    # Fallback silently if dotenv is not available
    pass
MONGODB_URI = os.getenv("MONGODB_URI", "mongodb://localhost:27017")
MONGODB_DB = os.getenv("MONGODB_DB", "ielts_go")

_mongo_client: Optional[AsyncIOMotorClient] = None

def _get_mongo_client() -> Optional[AsyncIOMotorClient]:
    global _mongo_client
    if AsyncIOMotorClient is None:
        return None
    if _mongo_client is None:
        _mongo_client = AsyncIOMotorClient(MONGODB_URI)
    return _mongo_client

def _get_db():
    client = _get_mongo_client()
    return client[MONGODB_DB] if client else None

def _ensure_data_dir():
    os.makedirs(DATA_DIR, exist_ok=True)

def load_tests() -> List[ReadingTest]:
    _ensure_data_dir()
    if not os.path.exists(TESTS_FILE):
        # Create sample data if not present
        sample = {
            "tests": [
                {
                    "id": "cambridge-15-test-1",
                    "source": "Cambridge IELTS 15 Test 1 (sample)",
                    "passages": [
                        {
                            "id": "p1",
                            "title": "The History of Tea",
                            "text": "Tea has been consumed for centuries..."
                        }
                    ],
                    "questions": [
                        {
                            "id": "q1",
                            "type": "TrueFalseNotGiven",
                            "prompt": "Tea originated in Europe.",
                            "answer": "False",
                            "passage_id": "p1"
                        },
                        {
                            "id": "q2",
                            "type": "MultipleChoice",
                            "prompt": "Which country is most associated with the origins of tea?",
                            "options": ["India", "China", "Japan", "UK"],
                            "answer": "China",
                            "passage_id": "p1"
                        },
                        {
                            "id": "q3",
                            "type": "MatchingHeadings",
                            "prompt": "Match the paragraph with the heading.",
                            "options": ["Origins", "Trade Expansion", "Cultural Impact"],
                            "answer": "Origins",
                            "passage_id": "p1"
                        },
                        {
                            "id": "q4",
                            "type": "FillInTheBlanks",
                            "prompt": "Tea has been consumed for _____.",
                            "answer": "centuries",
                            "passage_id": "p1"
                        }
                    ]
                }
            ]
        }
        with open(TESTS_FILE, "w", encoding="utf-8") as f:
            json.dump(sample, f, ensure_ascii=False, indent=2)
    with open(TESTS_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
    return [ReadingTest(**t) for t in data.get("tests", [])]

async def _seed_tests_if_empty() -> None:
    db = _get_db()
    if db is None:
        return
    count = await db.reading_tests.count_documents({})
    if count == 0:
        tests = [t.model_dump() for t in load_tests()]
        if tests:
            await db.reading_tests.insert_many(tests)

async def _ensure_seed_once() -> None:
    # Run seeding once at startup
    db = _get_db()
    if db is not None:
        await _seed_tests_if_empty()

async def get_test_by_id(test_id: str) -> Optional[ReadingTest]:
    print(f"ğŸ” get_test_by_id Ã§aÄŸrÄ±ldÄ±: {test_id}")
    print(f"â„¹ï¸ Testler artÄ±k MongoDB'de kaydedilmiyor - sadece anlÄ±k AI'dan geliyor")
    print(f"âŒ Test bulunamadÄ±: {test_id} - Testler anlÄ±k olarak Ã¼retiliyor")
    return None

def strip_answers(test: ReadingTest) -> Dict[str, Any]:
    test_dict = test.model_dump()
    for q in test_dict["questions"]:
        if "answer" in q:
            q.pop("answer")
    return test_dict

def _levenshtein(a: str, b: str) -> int:
    a = a or ""
    b = b or ""
    la, lb = len(a), len(b)
    if la == 0:
        return lb
    if lb == 0:
        return la
    dp = list(range(lb + 1))
    for i in range(1, la + 1):
        prev = dp[0]
        dp[0] = i
        for j in range(1, lb + 1):
            tmp = dp[j]
            cost = 0 if a[i - 1] == b[j - 1] else 1
            dp[j] = min(
                dp[j] + 1,        # deletion
                dp[j - 1] + 1,    # insertion
                prev + cost       # substitution
            )
            prev = tmp
    return dp[lb]

def _similarity(a: str, b: str) -> float:
    a_norm = str(a).strip().lower()
    b_norm = str(b).strip().lower()
    if not a_norm and not b_norm:
        return 1.0
    dist = _levenshtein(a_norm, b_norm)
    max_len = max(1, max(len(a_norm), len(b_norm)))
    return max(0.0, 1.0 - dist / max_len)

def compute_raw_score(test: ReadingTest, user_answers: Dict[str, Any]) -> Dict[str, Any]:
    results = {}
    correct = 0
    partial = 0.0
    total = len(test.questions)
    for q in test.questions:
        ua = user_answers.get(q.id)
        is_correct = False
        
        # correct_answer alanÄ±nÄ± kontrol et (yeni format)
        correct_answer = getattr(q, 'correct_answer', None) or getattr(q, 'answer', None)
        
        if ua is not None and correct_answer is not None:
            if isinstance(correct_answer, list):
                is_correct = set(map(str, ua)) == set(map(str, correct_answer))
            else:
                # Multiple Choice iÃ§in index kontrolÃ¼
                if q.type == "Multiple Choice" and isinstance(correct_answer, int):
                    try:
                        user_choice = int(ua) if str(ua).isdigit() else -1
                        is_correct = user_choice == correct_answer
                    except:
                        is_correct = False
                else:
                    # DiÄŸer soru tipleri iÃ§in string karÅŸÄ±laÅŸtÄ±rma
                    is_correct = str(ua).strip().lower() == str(correct_answer).strip().lower()
                    
                # grant small partial credit for near-miss on FillInTheBlanks
                if not is_correct and q.type in ["Fill in the blanks", "FillInTheBlanks"]:
                    sim = _similarity(str(ua), str(correct_answer))
                    # consider >=0.8 as correct, otherwise accumulate partial ratio
                    if sim >= 0.8:
                        is_correct = True
                    else:
                        partial += max(0.0, min(0.5, (sim - 0.5) * 2))  # 0..0.5 partial
                        
        results[q.id] = {"correct_answer": correct_answer, "user_answer": ua, "is_correct": is_correct}
        if is_correct:
            correct += 1
    return {"correct": correct, "partial": round(partial, 2), "total": total, "details": results}

def estimate_band_from_raw(raw_correct: int) -> float:
    # IELTS Academic Reading Band Score Conversion Table
    # Based on official IELTS scoring system
    band_scores = {
        40: 9.0, 39: 9.0, 38: 8.5, 37: 8.5, 36: 8.0, 35: 8.0,
        34: 7.5, 33: 7.5, 32: 7.0, 31: 7.0, 30: 7.0, 29: 6.5,
        28: 6.5, 27: 6.5, 26: 6.0, 25: 6.0, 24: 6.0, 23: 5.5,
        22: 5.5, 21: 5.5, 20: 5.0, 19: 5.0, 18: 4.5, 17: 4.5,
        16: 4.0, 15: 4.0, 14: 4.0, 13: 3.5, 12: 3.5, 11: 3.0,
        10: 3.0, 9: 3.0, 8: 2.5, 7: 2.5, 6: 2.0, 5: 2.0,
        4: 1.5, 3: 1.5, 2: 1.0, 1: 1.0, 0: 0.0
    }
    
    # Clamp the score between 0-40
    clamped_score = max(0, min(40, raw_correct))
    return band_scores.get(clamped_score, 1.0)

async def ai_feedback(test: ReadingTest, score_summary: Dict[str, Any]) -> AIScoreFeedback:
    api_key = os.getenv("GEMINI_API_KEY", "")
    # Placeholder: if no key, return heuristic feedback
    correct = score_summary["correct"]
    total = score_summary["total"]
    band = estimate_band_from_raw(correct)
    if not api_key:
        strengths = []
        improvements = []
        accuracy = correct / max(1, total)
        if accuracy >= 0.75:
            strengths.append("Metin detaylarÄ±nÄ± doÄŸru yakalÄ±yorsunuz.")
        else:
            improvements.append("True/False/Not Given sorularÄ±nda ifadeyi metinle birebir kÄ±yaslayÄ±n.")
        if accuracy < 0.5:
            improvements.append("Zaman yÃ¶netimi ve skimming/scanning stratejilerini Ã§alÄ±ÅŸÄ±n.")
        tips = [
            "Paragraf baÅŸlÄ±klarÄ±nÄ± Ã¶nce okuyup ana fikri belirleyin.",
            "Ã–nce soru tipini analiz edip anahtar kelimeleri iÅŸaretleyin.",
            "Synonym ve parafrase dikkat edin; tuzaklara dÃ¼ÅŸmeyin.",
        ]
        return AIScoreFeedback(band_estimate=band, strengths=strengths, improvements=improvements, tips=tips)
    # AI path: use Gemini to produce strengths/improvements/tips
    try:
        import google.generativeai as genai  # type: ignore
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")
        prompt = (
            "You are an IELTS Reading examiner. Given a test summary, provide concise feedback "
            "in Turkish with 3 strengths, 3 improvements, and 3 tips. Keep it short and actionable.\n\n"
            f"Summary: correct={score_summary['correct']} of {score_summary['total']} (scaled)."
        )
        resp = await model.generate_content_async(prompt)  # type: ignore
        text = (resp.text or "").strip()
        strengths = []
        improvements = []
        tips = []
        # naive split
        for line in text.splitlines():
            ln = line.strip("- â€¢* ")
            if not ln:
                continue
            if len(strengths) < 3:
                strengths.append(ln)
            elif len(improvements) < 3:
                improvements.append(ln)
            elif len(tips) < 3:
                tips.append(ln)
        return AIScoreFeedback(
            band_estimate=band,
            strengths=strengths[:3] or ["Okuma stratejileri iyi."],
            improvements=improvements[:3] or ["Metinle ifadeyi karÅŸÄ±laÅŸtÄ±rÄ±n."],
            tips=tips[:3] or ["Zaman yÃ¶netimine dikkat."],
        )
    except Exception:
        # fallback to heuristic text
        return AIScoreFeedback(
            band_estimate=band,
            strengths=["AI entegrasyonu kullanÄ±labilir."],
            improvements=["Daha detaylÄ± analiz eklenecek."],
            tips=["GerÃ§ek sÄ±navlardan pratik yapÄ±n."],
        )

@app.get("/tests")
async def list_tests():
    db = _get_db()
    tests: List[ReadingTest] = []
    if db is not None:
        await _ensure_seed_once()
        cursor = db.reading_tests.find({}, {"_id": 0})
        docs = await cursor.to_list(length=1000)
        tests = [ReadingTest(**d) for d in docs]
    else:
        tests = load_tests()
    return {"tests": [strip_answers(t) for t in tests]}

@app.get("/tests/{test_id}")
async def get_test(test_id: str):
    print(f"ğŸ” Test ID aranÄ±yor: {test_id}")
    print(f"â„¹ï¸ Testler artÄ±k MongoDB'de kaydedilmiyor - sadece anlÄ±k AI'dan geliyor")
    print(f"âŒ Test bulunamadÄ±: {test_id} - Testler anlÄ±k olarak Ã¼retiliyor")
    raise HTTPException(status_code=404, detail="Test bulunamadÄ± - Testler anlÄ±k olarak Ã¼retiliyor")

@app.post("/submit")
async def submit_answers(payload: SubmitAnswersRequest):
    print(f"ğŸ” Submit endpoint Ã§aÄŸrÄ±ldÄ±")
    print(f"ğŸ“‹ Test ID: {payload.test_id}")
    print(f"ğŸ“ Cevaplar sayÄ±sÄ±: {len(payload.answers)}")
    print(f"ğŸ“Š Test data var mÄ±: {hasattr(payload, 'test_data')}")
    print(f"ğŸ“Š Test data deÄŸeri: {payload.test_data is not None if hasattr(payload, 'test_data') else 'N/A'}")
    
    # Test artÄ±k MongoDB'de deÄŸil - frontend'den gelen test verilerini kullan
    if not hasattr(payload, 'test_data') or not payload.test_data:
        print(f"âŒ Test verisi bulunamadÄ±")
        raise HTTPException(status_code=400, detail="Test verisi bulunamadÄ± - frontend'den test verisi gÃ¶nderilmeli")
    
    # Frontend'den gelen test verisini ReadingTest objesine Ã§evir
    try:
        print(f"ğŸ”„ Test verisi ReadingTest objesine Ã§evriliyor...")
        test = ReadingTest(**payload.test_data)
        print(f"âœ… Test verisi baÅŸarÄ±yla Ã§evrildi")
    except Exception as e:
        print(f"âŒ Test verisi Ã§evirme hatasÄ±: {str(e)}")
        raise HTTPException(status_code=400, detail=f"Test verisi formatÄ± hatalÄ±: {str(e)}")
    
    print(f"ğŸ”„ Puanlama baÅŸlÄ±yor...")
    raw = compute_raw_score(test, payload.answers)
    print(f"ğŸ“Š Ham puan: {raw}")
    # Include partial credit when scaling
    effective_correct = raw["correct"] + raw.get("partial", 0.0)
    
    # Test tipini kontrol et - practice test mi yoksa full test mi?
    is_practice_test = test.id.startswith("practice-")
    
    if is_practice_test:
        # Practice test iÃ§in 13 soru varsayÄ±yoruz
        scale_factor = 13 / max(1, raw["total"]) if raw["total"] < 13 else 1.0
        scaled_correct = int(round(effective_correct * scale_factor))
        band = estimate_band_from_raw(scaled_correct)
        feedback = await ai_feedback(test, {"correct": scaled_correct, "total": 13})
        total_questions = 13
    else:
        # IELTS reading toplam 40 soru varsayÄ±yoruz
        scale_factor = 40 / max(1, raw["total"]) if raw["total"] < 40 else 1.0
        scaled_correct = int(round(effective_correct * scale_factor))
        band = estimate_band_from_raw(scaled_correct)
        feedback = await ai_feedback(test, {"correct": scaled_correct, "total": 40})
        total_questions = 40

    # Save submission if DB available
    db = _get_db()
    if db is not None:
        doc = {
            "test_id": payload.test_id,
            "user_id": payload.user_id,
            "answers": payload.answers,
            "raw": raw,
            "scaled": {"correct": scaled_correct, "total": total_questions},
        }
        await db.reading_submissions.insert_one(doc)
    
    # Dashboard iÃ§in puan kaydetme
    print(f"ğŸ” Dashboard kaydetme baÅŸlÄ±yor...")
    print(f"ğŸ“‹ User ID: {payload.user_id}")
    print(f"ğŸ“Š Band Score: {band}")
    print(f"ğŸ“ Test Type: {'practice' if is_practice_test else 'full'}")
    
    try:
        import httpx
        dashboard_url = "http://localhost:8000/api/save-score"
        
        # Test tipini belirle
        test_type = "reading_practice" if is_practice_test else "reading_full"
        
        score_data = {
            "module": test_type,
            "band_score": float(band),
            "raw_score": raw["correct"],
            "total_questions": raw["total"],
            "topic": "Reading Test",
            "difficulty": "practice" if is_practice_test else "full",
            "test_date": datetime.datetime.now().isoformat(),
            "detailed_results": {
                "feedback": feedback.model_dump(),
                "scaled_correct": scaled_correct,
                "scaled_total": total_questions
            }
        }
        
        print(f"ğŸ“¦ Score Data: {score_data}")
        
        async with httpx.AsyncClient() as client:
            # Authorization header ekle
            headers = {}
            if payload.user_id:
                # JWT token oluÅŸtur (basit bir yaklaÅŸÄ±m)
                import jwt
                import os
                secret_key = os.getenv("JWT_SECRET_KEY", "your-secret-key-here")
                token = jwt.encode(
                    {"sub": payload.user_id, "exp": datetime.datetime.utcnow() + datetime.timedelta(hours=24)},
                    secret_key,
                    algorithm="HS256"
                )
                headers["Authorization"] = f"Bearer {token}"
                print(f"ğŸ” User ID: {payload.user_id} - Dashboard'a kaydediliyor...")
                print(f"ğŸ« Token: {token[:50]}...")
            else:
                print(f"âš ï¸ User ID bulunamadÄ± - Dashboard'a kaydedilemiyor")
                print(f"âš ï¸ Payload: {payload}")
                return
            
            response = await client.post(dashboard_url, json=score_data, headers=headers)
            if response.status_code == 200:
                print(f"âœ… Reading puanÄ± dashboard'a kaydedildi: {band}")
            else:
                print(f"âš ï¸ Dashboard'a kaydetme baÅŸarÄ±sÄ±z: {response.status_code} - {response.text}")
                
    except Exception as e:
        print(f"âš ï¸ Dashboard kaydetme hatasÄ±: {str(e)}")

    return {
        "test_id": payload.test_id,
        "raw": raw,
        "scaled": {"correct": scaled_correct, "total": total_questions},
        "band_estimate": band,
        "feedback": feedback.model_dump(),
    }

@app.post("/tests")
async def create_test(test: ReadingTest):
    db = _get_db()
    if db is None:
        raise HTTPException(status_code=500, detail="VeritabanÄ± baÄŸlÄ± deÄŸil")
    # Upsert by id
    await db.reading_tests.update_one({"id": test.id}, {"$set": test.model_dump()}, upsert=True)
    return {"ok": True, "id": test.id}

@app.post("/generate-practice")
async def generate_practice_test(request: Dict[str, Any]):
    """Reading pratik testi - 1 metin, 13 soru"""
    try:
        # Gemini API key kontrolÃ¼
        api_key = os.getenv("GEMINI_API_KEY", "YENÄ°_API_KEY_BURAYA")
        if not api_key:
            raise HTTPException(status_code=500, detail="Gemini API key bulunamadÄ±")
        
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        # Test ID oluÅŸtur
        import uuid
        test_id = f"practice-{uuid.uuid4().hex[:8]}"
        
        # Reading pratik test Ã¼ret
        prompt = """
IELTS Reading pratik testi oluÅŸtur. Format ÅŸÃ¶yle olmalÄ±:

1 akademik metin (1200-1500 kelime):
- Genel akademik konu veya bilimsel makale

Toplam 13 soru, Ã§eÅŸitli tiplerde:
- Multiple Choice (4 ÅŸÄ±klÄ±) - 5-6 soru
- True/False/Not Given - 3-4 soru
- Fill in the blanks - 3-4 soru

Ã–NEMLÄ°: Short answer questions SORMAYIN! Sadece yukarÄ±daki 3 tip soru kullanÄ±n.

Metin iÃ§in:
- BaÅŸlÄ±k
- Uzun akademik seviyede metin (1200+ kelime)
- Kelime sayÄ±sÄ± bilgisi

Her soru iÃ§in:
- Soru metni
- Tip bilgisi
- DoÄŸru cevap
- Passage ID (p1)

JSON formatÄ±nda dÃ¶ndÃ¼r:
{
  "id": "TEST_ID_PLACEHOLDER",
  "source": "IELTS Reading Practice Test",
  "passages": [
    {
      "id": "p1",
      "title": "Metin BaÅŸlÄ±ÄŸÄ±",
      "text": "Uzun metin iÃ§eriÄŸi... (1200+ kelime)",
      "word_count": 1250
    }
  ],
  "questions": [
     {
       "id": "q1",
       "type": "Multiple Choice",
       "prompt": "Soru metni",
       "options": ["A) SeÃ§enek 1", "B) SeÃ§enek 2", "C) SeÃ§enek 3", "D) SeÃ§enek 4"],
       "correct_answer": 0,
       "passage_id": "p1"
     },
     {
       "id": "q2",
       "type": "True/False/Not Given",
       "prompt": "Soru metni",
       "correct_answer": "True",
       "passage_id": "p1"
     },
     {
       "id": "q3",
       "type": "Fill in the blanks",
       "prompt": "CÃ¼mle _____ ile tamamlanÄ±r.",
       "correct_answer": "kelime",
       "passage_id": "p1"
     }
  ]
}

 KRÄ°TÄ°K: Her soru iÃ§in "correct_answer" alanÄ± ZORUNLU! BoÅŸ cevap kabul edilmez!
- Multiple Choice: INDEX numarasÄ± (0, 1, 2, 3)
- True/False/Not Given: "True", "False", veya "Not Given"
- Fill in the blanks: DoÄŸru kelime/cÃ¼mle

Ã–NEMLÄ° FORMAT KURALLARI:
- options alanÄ± MUTLAKA string array olmalÄ±: ["A) SeÃ§enek 1", "B) SeÃ§enek 2", "C) SeÃ§enek 3", "D) SeÃ§enek 4"]
- Dictionary formatÄ± YASAK: [{"A": "SeÃ§enek 1"}, {"B": "SeÃ§enek 2"}] âŒ
- passage_id alanÄ± MUTLAKA string olmalÄ±: "p1" (array deÄŸil!)

Ã–RNEK CEVAPLAR:
- Multiple Choice: 2 (Ã¼Ã§Ã¼ncÃ¼ seÃ§enek iÃ§in)
- True/False: "False"
- Fill in blanks: "mitigate"

KRÄ°TÄ°K KURALLAR:
- SADECE JSON dÃ¶ndÃ¼r, baÅŸka hiÃ§bir metin ekleme
- JSON'u ```json ile sarmalama
- Toplam 13 soru Ã¼ret
- Soru ID'leri: q1, q2, q3... q13
- JSON formatÄ±na dikkat et, virgÃ¼l hatalarÄ± yapma
- passage_id alanÄ± MUTLAKA string olmalÄ±: "p1" (array deÄŸil!)
"""
        
        # Test ID'yi prompt'a ekle
        final_prompt = prompt.replace("TEST_ID_PLACEHOLDER", test_id)
        response = await model.generate_content_async(final_prompt)
        content = response.text.strip()
        
        # Debug: AI'dan gelen ham veriyi kontrol et
        print(f"ğŸ¤– AI'dan gelen ham veri (ilk 500 karakter): {content[:500]}...")
        
        # JSON parse et - trailing comma ve diÄŸer hatalarÄ± dÃ¼zelt
        try:
            # ```json wrapper'Ä±nÄ± temizle
            if content.startswith("```json"):
                content = content[7:]
            if content.endswith("```"):
                content = content[:-3]
            
            # JSON temizleme - trailing comma'larÄ± kaldÄ±r
            import re
            # Dizi sonundaki virgÃ¼lleri kaldÄ±r: ], ] -> ]
            content = re.sub(r',\s*]', ']', content)
            # Obje sonundaki virgÃ¼lleri kaldÄ±r: }, } -> }
            content = re.sub(r',\s*}', '}', content)
            
            # Daha agresif temizleme - bozuk karakterleri dÃ¼zelt
            content = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x9f]', '', content)
            
            # JSON'u parse et
            test_data = json.loads(content)
            
            # Debug: Test verisini kontrol et
            print(f"ğŸ” Test verisi alÄ±ndÄ±: {test_data.get('id', 'NO_ID')}")
            if "questions" in test_data:
                print(f"ğŸ“ Toplam soru sayÄ±sÄ±: {len(test_data['questions'])}")
                if test_data["questions"]:
                    first_q = test_data["questions"][0]
                    print(f"ğŸ” Ä°lk soru: {first_q.get('id', 'NO_ID')}")
                    print(f"ğŸ” Ä°lk sorunun cevabÄ±: {first_q.get('answer', 'NO_ANSWER')}")
                    print(f"ğŸ” Ä°lk sorunun tipi: {first_q.get('type', 'NO_TYPE')}")
                    print(f"ğŸ” Ä°lk sorunun seÃ§enekleri: {first_q.get('options', 'NO_OPTIONS')}")
            
            # Soru ID'lerini dÃ¼zelt - sÄ±ralÄ± yap (q1, q2, q3... q13)
            if "questions" in test_data:
                for i, question in enumerate(test_data["questions"], 1):
                    question["id"] = f"q{i}"
                    
                    # Options formatÄ±nÄ± dÃ¼zelt (AI bazen dictionary gÃ¶nderiyor)
                    if "options" in question and question["options"]:
                        if isinstance(question["options"], list) and len(question["options"]) > 0:
                            if isinstance(question["options"][0], dict):
                                # Dictionary formatÄ±ndan string array'e Ã§evir
                                fixed_options = []
                                for opt_dict in question["options"]:
                                    for key, value in opt_dict.items():
                                        fixed_options.append(f"{key}) {value}")
                                question["options"] = fixed_options
                                print(f"ğŸ”§ Soru {i} options dÃ¼zeltildi: {len(fixed_options)} seÃ§enek")
                    
                    # passage_id array ise string'e Ã§evir
                    if "passage_id" in question and isinstance(question["passage_id"], list):
                        # Array'in ilk elemanÄ±nÄ± kullan veya boÅŸ ise p1
                        question["passage_id"] = question["passage_id"][0] if question["passage_id"] else "p1"
                        print(f"ğŸ”§ Soru {i} passage_id dÃ¼zeltildi: {question['passage_id']}")
                    
                    # correct_answer varsa answer'a da kopyala (geriye uyumluluk iÃ§in)
                    if "correct_answer" in question and question["correct_answer"] is not None:
                        question["answer"] = question["correct_answer"]
                        print(f"âœ… Soru {i} cevabÄ± var: {question.get('correct_answer')}")
                    elif not question.get("answer"):
                        print(f"âš ï¸ Soru {i} cevabÄ± boÅŸ!")
                        print(f"   Soru tipi: {question.get('type', 'NO_TYPE')}")
                        print(f"   Soru metni: {question.get('prompt', 'NO_PROMPT')[:100]}...")
                        print(f"   SeÃ§enekler: {question.get('options', 'NO_OPTIONS')}")
                        print(f"   âŒ AI'dan boÅŸ cevap geldi - bu dÃ¼zeltilmeli!")
            
            return test_data
            
        except json.JSONDecodeError as e:
            print(f"JSON parsing hatasÄ±: {str(e)}")
            print(f"Hata pozisyonu: Line {e.lineno}, Column {e.colno}")
            print(f"HatalÄ± JSON iÃ§eriÄŸi (ilk 1000 karakter): {content[:1000]}...")
            
            # Hata pozisyonu civarÄ±ndaki iÃ§eriÄŸi gÃ¶ster
            if e.lineno and e.colno:
                lines = content.split('\n')
                if e.lineno <= len(lines):
                    error_line = lines[e.lineno - 1] if e.lineno > 0 else ""
                    print(f"HatalÄ± satÄ±r ({e.lineno}): {error_line}")
                    if e.lineno > 1:
                        print(f"Ã–nceki satÄ±r ({e.lineno - 1}): {lines[e.lineno - 2] if e.lineno > 1 else ''}")
                    if e.lineno < len(lines):
                        print(f"Sonraki satÄ±r ({e.lineno + 1}): {lines[e.lineno] if e.lineno < len(lines) else ''}")
            
            raise HTTPException(status_code=500, detail=f"AI yanÄ±tÄ± JSON formatÄ±nda deÄŸil: {str(e)}")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Test Ã¼retme hatasÄ±: {str(e)}")

@app.post("/generate-ielts-academic")
async def generate_ielts_academic_test(request: Dict[str, Any]):
    """IELTS Academic Reading formatÄ±nda test Ã¼ret"""
    try:
        # Gemini API key kontrolÃ¼
        api_key = os.getenv("GEMINI_API_KEY", "YENÄ°_API_KEY_BURAYA")
        if not api_key:
            raise HTTPException(status_code=500, detail="Gemini API key bulunamadÄ±")
        
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")
        
        # Test ID oluÅŸtur
        import uuid
        test_id = f"ielts-academic-{uuid.uuid4().hex[:8]}"
        
        # IELTS Academic Reading test Ã¼ret
        prompt = """
IELTS Academic Reading testi oluÅŸtur. Format ÅŸÃ¶yle olmalÄ±:

3 akademik metin (her biri 1200-1500 kelime):
1. Genel akademik konu (13 soru)
2. Ä°ÅŸ dÃ¼nyasÄ±/EÄŸitim konusu (13 soru) 
3. Bilimsel/Akademik konu (14 soru)

Toplam 40 soru, Ã§eÅŸitli tiplerde:
- Multiple Choice (4 ÅŸÄ±klÄ±)
- True/False/Not Given
- Fill in the blanks
- Matching headings
- Matching information

Ã–NEMLÄ°: Short answer questions SORMAYIN! Sadece yukarÄ±daki 5 tip soru kullanÄ±n.

Her metin iÃ§in:
- BaÅŸlÄ±k
- Uzun akademik seviyede metin (1200+ kelime)
- Kelime sayÄ±sÄ± bilgisi

Her soru iÃ§in:
- Soru metni
- Tip bilgisi
- DoÄŸru cevap
- Passage ID (p1, p2, p3)

JSON formatÄ±nda dÃ¶ndÃ¼r:
{
  "id": "TEST_ID_PLACEHOLDER",
  "source": "IELTS Academic Reading Test",
  "passages": [
    {
      "id": "p1",
      "title": "Metin BaÅŸlÄ±ÄŸÄ±",
      "text": "Uzun metin iÃ§eriÄŸi... (1200+ kelime)",
      "word_count": 1250
    },
    {
      "id": "p2", 
      "title": "Ä°kinci Metin BaÅŸlÄ±ÄŸÄ±",
      "text": "Uzun metin iÃ§eriÄŸi... (1200+ kelime)",
      "word_count": 1300
    },
    {
      "id": "p3",
      "title": "ÃœÃ§Ã¼ncÃ¼ Metin BaÅŸlÄ±ÄŸÄ±", 
      "text": "Uzun metin iÃ§eriÄŸi... (1200+ kelime)",
      "word_count": 1280
    }
  ],
        "questions": [
            {
       "id": "q1",
       "type": "Multiple Choice",
       "prompt": "Soru metni",
       "options": ["A) SeÃ§enek 1", "B) SeÃ§enek 2", "C) SeÃ§enek 3", "D) SeÃ§enek 4"],
       "correct_answer": 0,
       "passage_id": "p1"
     },
     {
       "id": "q2",
       "type": "True/False/Not Given",
       "prompt": "Soru metni",
       "correct_answer": "True",
       "passage_id": "p1"
     },
     {
       "id": "q3",
       "type": "Fill in the blanks",
       "prompt": "CÃ¼mle _____ ile tamamlanÄ±r.",
       "correct_answer": "kelime",
       "passage_id": "p1"
     }
  ]
}

 KRÄ°TÄ°K: Her soru iÃ§in "correct_answer" alanÄ± ZORUNLU! BoÅŸ cevap kabul edilmez!
- Multiple Choice: INDEX numarasÄ± (0, 1, 2, 3)
- True/False/Not Given: "True", "False", veya "Not Given"
- Fill in the blanks: DoÄŸru kelime/cÃ¼mle
- Matching: EÅŸleÅŸen kelime/ifade

Ã–NEMLÄ° FORMAT KURALLARI:
- options alanÄ± MUTLAKA string array olmalÄ±: ["A) SeÃ§enek 1", "B) SeÃ§enek 2", "C) SeÃ§enek 3", "D) SeÃ§enek 4"]
- Dictionary formatÄ± YASAK: [{"A": "SeÃ§enek 1"}, {"B": "SeÃ§enek 2"}] âŒ

Ã–RNEK CEVAPLAR:
- Multiple Choice: 2 (Ã¼Ã§Ã¼ncÃ¼ seÃ§enek iÃ§in)
- True/False: "False"
- Fill in blanks: "mitigate"
- Matching: "Climate change"

KRÄ°TÄ°K KURALLAR:
- SADECE JSON dÃ¶ndÃ¼r, baÅŸka hiÃ§bir metin ekleme
- JSON'u ```json ile sarmalama
- Her metin iÃ§in 13-14 soru Ã¼ret
- Soru ID'leri: q1, q2, q3... q40
- JSON formatÄ±na dikkat et, virgÃ¼l hatalarÄ± yapma
- passage_id alanÄ± MUTLAKA string olmalÄ±: "p1", "p2", "p3" (array deÄŸil!)
"""
        
        # Test ID'yi prompt'a ekle
        final_prompt = prompt.replace("TEST_ID_PLACEHOLDER", test_id)
        response = await model.generate_content_async(final_prompt)
        content = response.text.strip()
        
        # Debug: AI'dan gelen ham veriyi kontrol et
        print(f"ğŸ¤– AI'dan gelen ham veri (ilk 500 karakter): {content[:500]}...")
        
        # JSON parse et - trailing comma ve diÄŸer hatalarÄ± dÃ¼zelt
        try:
            # ```json wrapper'Ä±nÄ± temizle
            if content.startswith("```json"):
                content = content[7:]
            if content.endswith("```"):
                content = content[:-3]
            
            # JSON temizleme - trailing comma'larÄ± kaldÄ±r
            import re
            # Dizi sonundaki virgÃ¼lleri kaldÄ±r: ], ] -> ]
            content = re.sub(r',\s*]', ']', content)
            # Obje sonundaki virgÃ¼lleri kaldÄ±r: }, } -> }
            content = re.sub(r',\s*}', '}', content)
            
            # Daha agresif temizleme - bozuk karakterleri dÃ¼zelt
            content = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x9f]', '', content)
            
            # JSON'u parse et
            test_data = json.loads(content)
            
            # Debug: Test verisini kontrol et
            print(f"ğŸ” Test verisi alÄ±ndÄ±: {test_data.get('id', 'NO_ID')}")
            if "questions" in test_data:
                print(f"ğŸ“ Toplam soru sayÄ±sÄ±: {len(test_data['questions'])}")
                # Ä°lk sorunun cevabÄ±nÄ± kontrol et
                if test_data["questions"]:
                    first_q = test_data["questions"][0]
                    print(f"ğŸ” Ä°lk soru: {first_q.get('id', 'NO_ID')}")
                    print(f"ğŸ” Ä°lk sorunun cevabÄ±: {first_q.get('answer', 'NO_ANSWER')}")
                    print(f"ğŸ” Ä°lk sorunun tipi: {first_q.get('type', 'NO_TYPE')}")
                    print(f"ğŸ” Ä°lk sorunun seÃ§enekleri: {first_q.get('options', 'NO_OPTIONS')}")
            
            # Soru ID'lerini dÃ¼zelt - sÄ±ralÄ± yap (q1, q2, q3... q40)
            if "questions" in test_data:
                for i, question in enumerate(test_data["questions"], 1):
                    question["id"] = f"q{i}"
                    
                    # Options formatÄ±nÄ± dÃ¼zelt (AI bazen dictionary gÃ¶nderiyor)
                    if "options" in question and question["options"]:
                        if isinstance(question["options"], list) and len(question["options"]) > 0:
                            if isinstance(question["options"][0], dict):
                                # Dictionary formatÄ±ndan string array'e Ã§evir
                                fixed_options = []
                                for opt_dict in question["options"]:
                                    for key, value in opt_dict.items():
                                        fixed_options.append(f"{key}) {value}")
                                question["options"] = fixed_options
                                print(f"ğŸ”§ Soru {i} options dÃ¼zeltildi: {len(fixed_options)} seÃ§enek")
                    
                    # passage_id array ise string'e Ã§evir
                    if "passage_id" in question and isinstance(question["passage_id"], list):
                        # Array'in ilk elemanÄ±nÄ± kullan veya boÅŸ ise p1
                        question["passage_id"] = question["passage_id"][0] if question["passage_id"] else "p1"
                        print(f"ğŸ”§ Soru {i} passage_id dÃ¼zeltildi: {question['passage_id']}")
                    
                    # correct_answer varsa answer'a da kopyala (geriye uyumluluk iÃ§in)
                    if "correct_answer" in question and question["correct_answer"] is not None:
                        question["answer"] = question["correct_answer"]
                        print(f"âœ… Soru {i} cevabÄ± var: {question.get('correct_answer')}")
                    elif not question.get("answer"):
                        print(f"âš ï¸ Soru {i} cevabÄ± boÅŸ!")
                        print(f"   Soru tipi: {question.get('type', 'NO_TYPE')}")
                        print(f"   Soru metni: {question.get('prompt', 'NO_PROMPT')[:100]}...")
                        print(f"   SeÃ§enekler: {question.get('options', 'NO_OPTIONS')}")
                        print(f"   âŒ AI'dan boÅŸ cevap geldi - bu dÃ¼zeltilmeli!")
            
            # Test'i veritabanÄ±na kaydetme - sadece anlÄ±k AI'dan gelsin
            # db = _get_db()
            # if db is not None:
            #     await db.reading_tests.update_one(
            #         {"id": test_data["id"]}, 
            #         {"$set": test_data}, 
            #         upsert=True
            #     )
            
            return test_data
            
        except json.JSONDecodeError as e:
            print(f"JSON parsing hatasÄ±: {str(e)}")
            print(f"Hata pozisyonu: Line {e.lineno}, Column {e.colno}")
            print(f"HatalÄ± JSON iÃ§eriÄŸi (ilk 1000 karakter): {content[:1000]}...")
            
            # Hata pozisyonu civarÄ±ndaki iÃ§eriÄŸi gÃ¶ster
            if e.lineno and e.colno:
                lines = content.split('\n')
                if e.lineno <= len(lines):
                    error_line = lines[e.lineno - 1] if e.lineno > 0 else ""
                    print(f"HatalÄ± satÄ±r ({e.lineno}): {error_line}")
                    if e.lineno > 1:
                        print(f"Ã–nceki satÄ±r ({e.lineno - 1}): {lines[e.lineno - 2] if e.lineno > 1 else ''}")
                    if e.lineno < len(lines):
                        print(f"Sonraki satÄ±r ({e.lineno + 1}): {lines[e.lineno] if e.lineno < len(lines) else ''}")
            
            raise HTTPException(status_code=500, detail=f"AI yanÄ±tÄ± JSON formatÄ±nda deÄŸil: {str(e)}")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Test Ã¼retme hatasÄ±: {str(e)}")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8001)
